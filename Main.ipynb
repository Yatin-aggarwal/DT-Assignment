{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d0a295-85a1-40dc-bd5f-08bfd0fec176",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Libraries\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbf6079-8cf5-4f69-b68d-a2e31cabe2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yatin\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# these are all libraies used in the code\n",
    "import pandas as pd \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List ,Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29965b89-604c-4a54-b466-17db23c84125",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Load Environment\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7149319-5cfc-4bff-a40a-0e4a3b68fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0779ca8-60c0-42c3-a434-8eca6e967fd5",
   "metadata": {},
   "source": [
    "<H1>\n",
    "    Data Load\n",
    "</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b74e03-8639-4b62-b47f-0f8450d9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_excel(\"Copy of DT Data Champion Assignment.xlsx\",sheet_name=[\"DataSet2 Advanced Screening\",\"DataSet1 Basic Screening\",\"Data Set4 Key Advanced2\",\"DataSet3 Key Basic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a779a-0ac2-4ba8-ac36-fefaa26714b9",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Questions\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9190334-a38d-4996-a998-ddc6d6aad059",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Basic_Question = Data[\"DataSet1 Basic Screening\"].columns[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e82ec2-54fb-43d4-a089-a2cc2cbad4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Advanced_Question = Data[\"DataSet2 Advanced Screening\"].columns[2:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b96c1-2123-4323-9c15-f74d2b1b9a0d",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Data Set\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c06988-794c-4508-b4c1-e2c35b708602",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Data = Data[\"DataSet2 Advanced Screening\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acf7ac8-888f-4605-81d9-c6b2c9cae9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Data = Data[\"DataSet1 Basic Screening\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dd8d7-0441-418d-977e-024857595fcc",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Key\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8bc1f9-634d-467a-9035-b6e96e3afacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Key =  Data[\"DataSet3 Key Basic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4940b71d-3ff1-4644-8610-7b80cfe66b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Key  = Data[\"Data Set4 Key Advanced2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ba6f4-b517-48da-a473-f052950dae15",
   "metadata": {},
   "source": [
    "<H1>\n",
    "    Data Pre-Processing\n",
    "</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28da02-2994-412f-9695-65011f0a5665",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Basic Data Pre-Processing\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de4919d-3ee1-4e33-897a-0461c4c6d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Data.columns = [Basic_Data.columns[0], Basic_Data.columns[1], \"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\n",
    "                      Basic_Data.columns[7],Basic_Data.columns[8],\n",
    "                      Basic_Data.columns[9],\"Ans1\",\"Ans2\",\"Ans3\",\"Ans4\",\"Ans5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15782d9a-7b71-4ba5-80a2-fbf9aca2c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Key.columns = [\"1\",\"2\",\"Question\", \"Marks\",\"Option\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23143bc-3877-4fa7-bab7-36cb1dff5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Key =  Basic_Key.drop([\"1\",\"2\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1102c578-fb08-46df-beab-42d1b2917a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Key  =  Basic_Key.dropna(how='all', axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f507150c-b03b-473a-8964-f17dd1ff33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = None\n",
    "Basic_Key_map = {}\n",
    "count= 0 \n",
    "for idx, i in Basic_Key.iterrows():\n",
    "    if pd.notna(i.Question):\n",
    "        Question  = All_Basic_Question[count]\n",
    "        Basic_Key_map[Question] = []\n",
    "        count+=1\n",
    "    Basic_Key_map[Question].append(i.Option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41067212-307e-45b8-92f1-8376da1a2ea4",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Advanced Data Pre-Processing\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60896bee-4879-4332-9759-dd82890ecc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Data.columns = [Advanced_Data.columns[0], Advanced_Data.columns[1], \"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\n",
    "                         \"Q6\",\"Q7\",\"Q8\",\"Q9\",\"Q10\",\n",
    "                         \"Name\",\n",
    "                         Advanced_Data.columns[13],Basic_Data.columns[14],\"Ans1\",\"Ans2\",\"Ans3\",\"Ans4\",\n",
    "                         \"Ans5\",\"Ans6\",\"Ans7\",\"Ans8\",\"Ans9\",\"Ans10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfe279d-8837-4b5a-9aa1-257724351ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Key.columns = [\"1\",\"2\",\"Question\", \"Marks\",\"Option\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e3b5d9-46c7-4799-adb3-ab1a962a77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Key =  Advanced_Key.drop([\"1\",\"2\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d307ccf-f8be-4ba5-be67-5eccc906f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_Key  =  Advanced_Key.dropna(how='all', axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795658eb-7df5-4f78-a98c-7dab4d6296b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = None\n",
    "count = 0 \n",
    "Advanced_Key_map = {}\n",
    "for idx, i in Advanced_Key.iterrows():\n",
    "    if pd.notna(i.Question):\n",
    "        Question  =  All_Advanced_Question[count]\n",
    "        Advanced_Key_map[Question] = []\n",
    "        count+=1\n",
    "    Advanced_Key_map[Question].append(i.Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ade10e-13af-4645-90a8-9f7e42934b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb03bb7-3b09-4ca4-903a-433e71390a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"\"\" You are an Human analyst trying to evaluate candiate based on Risk-taking(adventurousness), self-learning, \n",
    "            sense of achievement , cross-functional thinking and ability to take feedback. For this purpose few question are prepared and \n",
    "            there are 4 options from which user can select any one of them. You have to rate out of 4 every option. You must give rating for each\n",
    "            and every 5 criteria( Risk-taking(adventurousness), self-learning, sense of achievement , cross-functional thinking and ability to take feedback)\n",
    "            mentioned above. Also while rating option you should not biased to any option weight every option indvidually. \n",
    "            You have to only give option number criteria you are rating and rating for the criteria nothing else. \n",
    "            It sructure must be like this [   Risk-taking(adventurousness):3 , self-learning:2, sense of achievement , \n",
    "            cross-functional thinking:1 ability to take feedback:5]. {format_instructions}. {question} and these are {options} to the question.\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "477d6bd0-0d7c-4937-8060-557541731c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    Question: str = Field(description=\"Question number in the form Q1 only nothing else. \")\n",
    "    Options:List[Dict[str,str]] = Field(description=\"Specify all options\")\n",
    "    Rating: Dict[int,Dict[str,str]] = Field(description=\"Rating on the basis of given criterias of options based on question. Same format as input option, do not use keyword option to depect option use interger 0,1,2,3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a96f4d9d-aa3d-4801-8303-f78516c9f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rating(Query, Dict, LLM):\n",
    "    parser = JsonOutputParser(pydantic_object=Output)\n",
    "    prompt = PromptTemplate(\n",
    "            template=Query,\n",
    "            input_variables=[\"question\", \"options\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "    chain = prompt | LLM | parser\n",
    "    result = []\n",
    "    for i in Dict.keys():\n",
    "        result.append(chain.invoke({\n",
    "            \"question\":i,\n",
    "            \"options\":Dict[i]\n",
    "            }))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3c51ae-75b5-414f-902f-4abfb7d3d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_ratings = Rating(Query, Basic_Key_map, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c52f28-5afd-4586-9f2a-cb029f1afcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_ratings = Rating(Query,Advanced_Key_map,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80e43da6-bbf2-40a4-a25f-9f1ddef6aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Key = Basic_Key.ffill()\n",
    "Advanced_Key = Advanced_Key.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d999914d-db7c-48a3-97db-5c7048c016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Basic_Key['Question'].unique():\n",
    "    q1 = Basic_Key.loc[Basic_Key['Question']==i]['Option'].unique()\n",
    "    count = 0 \n",
    "    for j in q1:\n",
    "        Basic_Key.loc[(Basic_Key['Question'] == i) & (Basic_Key['Option'] == j), 'Option']= count\n",
    "        Basic_Data.loc[Basic_Data[i] == j,i] = count\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffa15f80-e579-4784-8b55-1c3129d2e628",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in Advanced_Key['Question'].unique():\n",
    "    q1 = Advanced_Key.loc[Advanced_Key['Question']==i]['Option'].unique()\n",
    "    count = 0 \n",
    "    for j in q1:\n",
    "        Advanced_Key.loc[(Advanced_Key['Question'] == i) & (Advanced_Key['Option'] == j), 'Option']= count\n",
    "        Advanced_Data.loc[Advanced_Data[i] == j,i] = count\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92ae5957-3038-447b-994f-f1481aef2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Data['self-learning'] = 0\n",
    "Basic_Data['sense of achievement'] = 0\n",
    "Basic_Data['cross-functional thinking'] = 0\n",
    "Basic_Data['ability to take feedback'] = 0\n",
    "Basic_Data['Risk-taking(adventurousness)'] = 0\n",
    "\n",
    "\n",
    "Advanced_Data['self-learning'] = 0\n",
    "Advanced_Data['sense of achievement'] = 0\n",
    "Advanced_Data['cross-functional thinking'] = 0\n",
    "Advanced_Data['ability to take feedback'] = 0\n",
    "Advanced_Data['Risk-taking(adventurousness)'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698a2f18-fedf-4b33-830f-eabe17577750",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = ['self-learning','sense of achievement','cross-functional thinking','ability to take feedback','Risk-taking(adventurousness)']\n",
    "Basic_question = ['Q1', 'Q2','Q3','Q4','Q5']\n",
    "Advanced_question = ['Q1', 'Q2','Q3','Q4','Q5','Q6', 'Q7','Q8','Q9','Q10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e9bb361-40ce-44bc-ace5-740c2607e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr, i in Basic_Data.iterrows():\n",
    "    for j in range(0,len(Basic_question)):\n",
    "        for k in para:\n",
    "            Basic_Data.at[itr,k] = Basic_Data.at[itr,k] + int(basic_ratings[j]['Rating'][str(i[Basic_question[j]])][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a24d2d81-1f99-42af-9402-5aaf30e33523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr, i in Advanced_Data.iterrows():\n",
    "    for j in range(0,len(Advanced_question)):\n",
    "        for k in para:\n",
    "            t = 0 \n",
    "            try:\n",
    "                 t =  int(advanced_ratings[j]['Rating'][str(i[Advanced_question[j]])][k])\n",
    "            except:\n",
    "                 t = 0\n",
    "            Advanced_Data.at[itr,k] = Advanced_Data.at[itr,k] + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd8dbf59-653d-4108-9f00-efdf83e05123",
   "metadata": {},
   "outputs": [],
   "source": [
    "Suggestive_query = \"\"\"you are an expert reviewer who has to give feedback to students based on their response \n",
    "in assessment. There were two test conducte one was basic while other was advanced. All students had given basic test but \n",
    "some had not attempted advanced test. There 5 criterion(Risk-taking(adventurousness), self-learning, sense of achievement , cross-functional thinking and ability to \n",
    "take feedback) to evaluate each option of a question. Each option given score out of 4 based on criteria. Since it is not possible\n",
    "to achive full 4 points in criteria. However best option usually achive full marks in 2-3 criteria. Since all option marked by students are marked and evaluated \n",
    "score of eachh criterion is added to get final total score of each criterion. Score basic and adanced test are collectively. Since \n",
    "none student can get full score in criterion reciving score above 60 in a specific criterion is considered good for that criterion. \n",
    "write review recommending students area where they can work and improve.Also give some suggestion student can follow to improve above criterion.  \n",
    "Basic Test Scores based on 5 criterion:\n",
    "self-learning:{Basic-self-learning},\n",
    "sense of achievement:{Basic-sense of achievement},\n",
    "cross-functional thinking:{Basic-cross-functional thinking},\n",
    "ability to take feedback:{Basic-ability to take feedback} and\n",
    "Risk-taking(adventurousness): {Basic-Risk-taking(adventurousness)}\n",
    "\n",
    "Advanced Test Scores based on 5 criterion:\n",
    "self-learning:{Advanced-self-learning},\n",
    "sense of achievement:{Advanced-sense of achievement},\n",
    "cross-functional thinking:{Advanced-cross-functional thinking},\n",
    "ability to take feedback:{Advanced-ability to take feedback} and\n",
    "Risk-taking(adventurousness): {Advanced-Risk-taking(adventurousness)}\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c83a1a3c-1a8d-4efa-b379-47ada1d6aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge = pd.merge(Basic_Data,Advanced_Data, on=\"Name\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ed7e923-7e59-464f-8725-590007bdf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review_Structure(BaseModel):\n",
    "    feedback: str = Field(description=\"Give feedback based on scores of Basic and advanced criterion\")\n",
    "    suggestion: str = Field(description=\"Give suggestion to improve score \")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02f118eb-5d5d-465a-bf13-91b17191664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rating(Row, LLM):\n",
    "    parser = JsonOutputParser(pydantic_object=Review_Structure)\n",
    "    prompt = PromptTemplate(\n",
    "            template=Suggestive_query,\n",
    "            input_variables=[\"Basic-self-learning\", \"Basic-sense of achievement\",\"Basic-cross-functional thinking\", \"Basic-ability to take feedback\"\n",
    "                            ,\"Basic-Risk-taking(adventurousness)\",\"Advanced-self-learning\",\"Advanced-sense of achievement\",\"Advanced-cross-functional thinking\",\n",
    "                             \"Advanced-ability to take feedback\",\"Advanced-Risk-taking(adventurousness)\"\n",
    "                            ],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "    chain = prompt | LLM | parser\n",
    "    result = chain.invoke({\n",
    "            \"Basic-self-learning\":Row['self-learning_x'], \"Basic-sense of achievement\":Row['sense of achievement_x'],\"Basic-cross-functional thinking\":Row['cross-functional thinking_x'], \"Basic-ability to take feedback\":Row['ability to take feedback_x']\n",
    "            ,\"Basic-Risk-taking(adventurousness)\":Row['Risk-taking(adventurousness)_x'],\"Advanced-self-learning\":Row['self-learning_y'],\"Advanced-sense of achievement\":Row['sense of achievement_y'],\"Advanced-cross-functional thinking\":Row['cross-functional thinking_y'],\n",
    "            \"Advanced-ability to take feedback\":Row['ability to take feedback_y'],\"Advanced-Risk-taking(adventurousness)\":Row['Risk-taking(adventurousness)_y']\n",
    "            })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53de515b-b254-4a54-a98b-9b2a3e87e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = pd.DataFrame(columns=[\"Name\",\"Feedback\",\"Suggestion\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ae0732c-3e23-46e9-88c5-a3581855995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr , row in Merge.iterrows():\n",
    "    response = Rating(row,llm)\n",
    "    feedback = feedback._append({\"Name\":row['Name'],\"Feedback\":response[\"feedback\"],\"Suggestion\":response[\"suggestion\"]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65b19ec0-4f71-4e26-9e3e-5aeb2837caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.to_excel(\"Feedback.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba5513-9b5d-4d9a-a8d3-7b66db10e419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
